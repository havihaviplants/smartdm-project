from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import OpenAI
import os

from utils.parser import parse_question, get_manual_text, get_sheet_info

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_SHEET_ID = os.getenv("GOOGLE_SHEET_ID")

if not OPENAI_API_KEY:
    raise RuntimeError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
if not GOOGLE_SHEET_ID:
    raise RuntimeError("âŒ GOOGLE_SHEET_IDê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ğŸ”— OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìµœì‹  SDK ë°©ì‹)
client = OpenAI(api_key=OPENAI_API_KEY)

# ğŸŒ FastAPI ì•±
app = FastAPI()

# âœ… CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“¥ ìš”ì²­ ëª¨ë¸
class Question(BaseModel):
    question: str
    use_gpt4: bool = False

@app.get("/")
async def root():
    return {"message": "Smart Parser API is running."}

@app.get("/test-manual")
async def test_manual():
    try:
        return {"manual": get_manual_text()[:300]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë§¤ë‰´ì–¼ ë¡œë”© ì‹¤íŒ¨: {e}")

@app.get("/debug-manual")
def debug_manual():
    return {"manual": get_manual_text()}

@app.post("/ask")
async def ask_question(payload: Question):
    try:
        parsed = parse_question(payload.question)
        manual = get_manual_text()
        sheet_summary = get_sheet_info(GOOGLE_SHEET_ID)

        if not manual or "ìƒë‹´ ë§¤ë‰´ì–¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." in manual:
            return {
                "answer": "â— ìƒë‹´ ë§¤ë‰´ì–¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "model": "manual_missing",
                "parsed": parsed
            }

        prompt = f"""
ì•„ë˜ëŠ” ìƒë‹´ì„ ìœ„í•œ ë§¤ë‰´ì–¼ê³¼ ì°¸ê³ ìš© ì‹œíŠ¸ ì •ë³´ì…ë‹ˆë‹¤.

ğŸ“˜ ìƒë‹´ ë§¤ë‰´ì–¼:
{manual}

ğŸ“Š ì°¸ê³ ìš© ì‹œíŠ¸ ìš”ì•½:
{sheet_summary}

ì´ ìë£Œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•´ ì£¼ì„¸ìš”.
ì§ˆë¬¸: {payload.question}
"""

        model = "gpt-4" if payload.use_gpt4 else "gpt-3.5-turbo"

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë§¤ë‰´ì–¼ê³¼ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ì°¸ê³ í•´ ì •í™•í•˜ê²Œ ì‘ë‹µí•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ìƒë‹´ ë„ìš°ë¯¸ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        return {
            "answer": response.choices[0].message.content.strip(),
            "model": model,
            "parsed": parsed
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPT ì‘ë‹µ ì‹¤íŒ¨: {e}")

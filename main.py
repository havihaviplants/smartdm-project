from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import openai
from utils.parser import parse_question, get_manual_text  # utilsì— í†µí•© ê°€ì •

# ğŸ” í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise RuntimeError("OPENAI_API_KEYê°€ .envì— ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

client = openai.OpenAI(api_key=openai_api_key)

# ğŸŒ FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# âœ… CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“¥ ìš”ì²­ ë°ì´í„° ëª¨ë¸
class Question(BaseModel):
    question: str
    use_gpt4: bool = False

# âœ… ê¸°ë³¸ ë£¨íŠ¸
@app.get("/")
async def root():
    return {"message": "Smart Parser API is running."}

# ğŸ§ª ìƒë‹´ ë§¤ë‰´ì–¼ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸
@app.get("/test-manual")
async def test_manual():
    try:
        manual = get_manual_text()
        return {"manual": manual[:300]}  # ì•ë¶€ë¶„ë§Œ í™•ì¸ìš©
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë§¤ë‰´ì–¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ğŸ¯ ì§ˆë¬¸ ì‘ë‹µ ì—”ë“œí¬ì¸íŠ¸
@app.post("/ask")
async def ask_question(payload: Question):
    try:
        parsed = parse_question(payload.question)
        manual = get_manual_text()

        if "ìƒë‹´ ë§¤ë‰´ì–¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." in manual:
            return {
                "answer": "ì£„ì†¡í•˜ì§€ë§Œ ìƒë‹´ ë§¤ë‰´ì–¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì–´ ì •í™•í•œ ë‹µë³€ì´ ì–´ë µìŠµë‹ˆë‹¤.",
                "model": "none",
                "parsed": parsed
            }

        prompt = f"""
ë‹¤ìŒì€ ìƒë‹´ ë§¤ë‰´ì–¼ì…ë‹ˆë‹¤. ë‚©ê¸°ì¼, ë§ˆê°ì¼, ì‘ëŒ€ ê¸°ì¤€ ë“±ì˜ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

{manual}

ìœ„ ë§¤ë‰´ì–¼ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

ì§ˆë¬¸: {payload.question}
"""

        model = "gpt-4" if payload.use_gpt4 else "gpt-3.5-turbo"

        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” ìƒë‹´ ë§¤ë‰´ì–¼ì„ ì˜ ì´í•´í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•˜ëŠ” ìŠ¤ë§ˆíŠ¸í•œ ìƒë‹´ ë„ìš°ë¯¸ì•¼."
                },
                {"role": "user", "content": prompt}
            ]
        )

        return {
            "answer": response.choices[0].message.content,
            "model": model,
            "parsed": parsed
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPT ì‘ë‹µ ì‹¤íŒ¨: {e}")

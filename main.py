from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import OpenAI
from utils.parser import parse_question, get_manual_text
import os

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise RuntimeError("[í™˜ê²½ì„¤ì • ì˜¤ë¥˜] OPENAI_API_KEYê°€ .envì— ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ğŸ¤– OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client: OpenAI = OpenAI(api_key=openai_api_key)

# ğŸŒ FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI()

# âœ… CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“¥ ìš”ì²­ ëª¨ë¸ ì •ì˜
class Question(BaseModel):
    question: str
    use_gpt4: bool = False

# ğŸ  ê¸°ë³¸ ë£¨íŠ¸
@app.get("/")
async def root():
    return {"message": "Smart Parser API is running."}

# ğŸ§ª ë§¤ë‰´ì–¼ í™•ì¸ìš© í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/test-manual")
async def test_manual():
    try:
        manual = get_manual_text()
        return {"manual": manual[:300]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"âŒ ë§¤ë‰´ì–¼ ë¡œë”© ì‹¤íŒ¨: {e}")

# ğŸ“¦ ë§¤ë‰´ì–¼ ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬
@app.post("/ask")
async def ask_question(payload: Question):
    try:
        parsed = parse_question(payload.question)
        manual = get_manual_text()

        if not manual or "ìƒë‹´ ë§¤ë‰´ì–¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." in manual:
            return {
                "answer": "â— ìƒë‹´ ë§¤ë‰´ì–¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "model": "manual_missing",
                "parsed": parsed
            }

        prompt = (
            f"ë‹¤ìŒì€ ìƒë‹´ ë§¤ë‰´ì–¼ì…ë‹ˆë‹¤. ë‚©ê¸°ì¼, ë§ˆê°ì¼, ì‘ëŒ€ ê¸°ì¤€ ë“±ì˜ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n\n"
            f"{manual}\n\n"
            f"ìœ„ ë§¤ë‰´ì–¼ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\n"
            f"ì§ˆë¬¸: {payload.question}"
        )

        model_name = "gpt-4" if payload.use_gpt4 else "gpt-3.5-turbo"

        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” ìƒë‹´ ë§¤ë‰´ì–¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µí•˜ëŠ” ìŠ¤ë§ˆíŠ¸í•œ ìƒë‹´ ë„ìš°ë¯¸ì•¼."
                },
                {"role": "user", "content": prompt}
            ]
        )

        answer = response.choices[0].message.content.strip()

        return {
            "answer": answer,
            "model": model_name,
            "parsed": parsed
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"âŒ GPT ì‘ë‹µ ì‹¤íŒ¨: {e}")

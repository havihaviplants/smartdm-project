from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import OpenAI
import os

from utils.parser import parse_question, get_manual_text, get_sheet_info, build_prompt, call_chat_model

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_SHEET_ID = os.getenv("GOOGLE_SHEET_ID")

if not OPENAI_API_KEY:
    raise RuntimeError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
if not GOOGLE_SHEET_ID:
    raise RuntimeError("âŒ GOOGLE_SHEET_IDê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

client = OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Question(BaseModel):
    question: str
    use_gpt4: bool = False

@app.get("/")
async def root():
    return {"message": "Smart Parser API is running."}

@app.get("/test-manual")
async def test_manual():
    try:
        return {"manual": get_manual_text()[:300]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"[manual] ë¡œë”© ì‹¤íŒ¨: {e}")

@app.get("/debug-manual")
def debug_manual():
    return {"manual": get_manual_text()}

@app.post("/ask")
async def ask_question(payload: Question):
    try:
        parsed = parse_question(payload.question)
        manual = get_manual_text()
        sheet_summary = get_sheet_info(GOOGLE_SHEET_ID)

        if not manual or "ìƒë‹´ ë§¤ë‰´ì–¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." in manual:
            return {
                "answer": "â— ìƒë‹´ ë§¤ë‰´ì–¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "model": "manual_missing",
                "parsed": parsed
            }

        prompt = build_prompt(manual, sheet_summary, payload.question)
        model = "gpt-4" if payload.use_gpt4 else "gpt-3.5-turbo"
        answer = call_chat_model(client, model, prompt)

        return {
            "answer": answer,
            "model": model,
            "parsed": parsed
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"[GPT] ì‘ë‹µ ì‹¤íŒ¨: {e}")
